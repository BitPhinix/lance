{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lance\n",
    "from lance.sampler import build_shuffle_sample\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an example dataset\n",
    "nrows = 1024 * 1024\n",
    "ndim = 768\n",
    "vecs = pa.FixedSizeListArray.from_arrays(pc.random(nrows * ndim).cast(\"float32\"), ndim)\n",
    "tab = pa.table({\n",
    "    \"id\": pa.array(range(nrows)),\n",
    "    \"vec\": vecs\n",
    "})\n",
    "ds = lance.write_dataset(tab, \"sample_dataset\", mode=\"overwrite\")\n",
    "del tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = lance.dataset(\"sample_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetSample(params=SampleParams(predicate='id > 200', batch_size=128, shuffle=True, sample_rate=None, seed=782193499428547259), row_id_mask=Mask<n=1048375>, batch_starts=PrimitiveArray<UInt32>\n",
       "[\n",
       "  994761,\n",
       "  220617,\n",
       "  282825,\n",
       "  927689,\n",
       "  864585,\n",
       "  20937,\n",
       "  565193,\n",
       "  191945,\n",
       "  546761,\n",
       "  56265,\n",
       "  ...8171 elements...,\n",
       "  832201,\n",
       "  879817,\n",
       "  92233,\n",
       "  349001,\n",
       "  573385,\n",
       "  1010377,\n",
       "  526537,\n",
       "  787785,\n",
       "  444233,\n",
       "  922185,\n",
       "], batch_lengths=PrimitiveArray<UInt16>\n",
       "[\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  ...8171 elements...,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "], metrics=SampleMetrics(dataset_size=1048576, matched_rows=1048375, sampled_rows=1048375))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = build_shuffle_sample(ds, predicate=\"id > 200\", batch_size=128)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples allow introspection\n",
    "\n",
    "Samples store information about the dataset, which can be used to understand the\n",
    "sample and the quality of it. This includes the originally parameters, as well\n",
    "as the seed chosen (or the one that was provided) so the sample can be reproduced.\n",
    "\n",
    "There are also metrics which can show how many rows were matched by the predicate\n",
    "and how many were sampled (if `sample_rate` was specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample covers 1048375 rows in 8191 batches\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample covers {} rows in {} batches\".format(sample.num_rows, len(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleParams(predicate='id > 200', batch_size=128, shuffle=True, sample_rate=None, seed=4160125278387179401)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicate matched 99.98% of the dataset\n"
     ]
    }
   ],
   "source": [
    "matched_percent = sample.metrics.matched_rows / sample.metrics.dataset_size\n",
    "print(\"The predicate matched {:.2%} of the dataset\".format(matched_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = build_shuffle_sample(ds, predicate=\"id > 200\", batch_size=128, sample_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample retrieved 19.89% of the dataset\n"
     ]
    }
   ],
   "source": [
    "sample_percent = sample.metrics.sampled_rows / sample.metrics.dataset_size\n",
    "print(\"The sample retrieved {:.2%} of the dataset\".format(sample_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Samples\n",
    "\n",
    "Samples can be sliced to get a subset of the sample. This is useful for distributed\n",
    "training, where each worker might select a different slice of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = 10\n",
    "worker_i = 3\n",
    "\n",
    "sample_slice = sample[worker_i::num_workers]\n",
    "len(sample_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing can also be used to skip batches, which is useful for resuming training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip = 10\n",
    "len(sample_slice[skip:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing Samples\n",
    "\n",
    "Samples can be serialized, which is useful for distributed training.\n",
    "\n",
    "The simplest way to serialize is using pickle, which can either be written into\n",
    "a file or saved as bytes in-memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"sample_slice.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sample_slice, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging purposes, you can also save the sample as a GZIP-compressed TAR archive.\n",
    "This can be opened and inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_slice.serialize_into(\"sample_slice.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x params.json\n",
      "x metrics.json\n",
      "x row_id_mask.bin\n",
      "x batches.arrow\n",
      "total 120\n",
      "-rw-r--r--  1 willjones  staff   5.6K Dec 31  1969 batches.arrow\n",
      "-rw-r--r--  1 willjones  staff    82B Dec 31  1969 metrics.json\n",
      "-rw-r--r--  1 willjones  staff   122B Dec 31  1969 params.json\n",
      "-rw-r--r--  1 willjones  staff    41K Dec 31  1969 row_id_mask.bin\n"
     ]
    }
   ],
   "source": [
    "# decompress and list contents of the archive\n",
    "!rm -rf sample_slice\n",
    "!mkdir sample_slice\n",
    "!tar -vxf sample_slice.tar.gz -C ./sample_slice/\n",
    "!ls -lh sample_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from a Sample\n",
    "\n",
    "The sample can be passed to data loader methods.\n",
    "\n",
    "The underlying mechanism is simply that the sample is Iterable, and returns\n",
    "an iterator of batch indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  218427,\n",
      "  218428,\n",
      "  218430,\n",
      "  218431,\n",
      "  218441,\n",
      "  218443,\n",
      "  218446,\n",
      "  218447,\n",
      "  218449,\n",
      "  218453,\n",
      "  ...\n",
      "  218532,\n",
      "  218533,\n",
      "  218538,\n",
      "  218543,\n",
      "  218544,\n",
      "  218545,\n",
      "  218548,\n",
      "  218550,\n",
      "  218551,\n",
      "  218554\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for batch in sample:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "id: int64\n",
       "vec: fixed_size_list<item: float>[768]\n",
       "  child 0, item: float\n",
       "----\n",
       "id: [[218427,218428,218430,218431,218441,...,218545,218548,218550,218551,218554]]\n",
       "vec: [[[0.039365917,0.9347307,0.17798844,0.49374506,0.7373791,...,0.67922693,0.569175,0.82238936,0.45353127,0.3069117],[0.28323245,0.93013906,0.7872263,0.44097242,0.5217537,...,0.0035082009,0.054516055,0.8780995,0.009865927,0.30937225],...,[0.50098234,0.9499888,0.69663125,0.9786897,0.4081945,...,0.9559047,0.60340804,0.06629784,0.90485907,0.14169064],[0.1103932,0.62449497,0.39245197,0.12508623,0.2733724,...,0.1418554,0.9146605,0.3044245,0.52509713,0.9617853]]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_iter(sample):\n",
    "    for indices in sample:\n",
    "        # TODO: LanceDataset.take should accept a pyarrow array\n",
    "        yield ds.take(indices.to_pylist())\n",
    "\n",
    "next(iter(batch_iter(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only single-threaded, so in most production use cases you'll instead want\n",
    "to use one of the data loaders, which will use multiple threads to read batches\n",
    "ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lance-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
